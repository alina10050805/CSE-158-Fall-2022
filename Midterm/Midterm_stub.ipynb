{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0e39c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will suppress any warnings, comment out if you'd like to preserve them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatting of submissions\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "84568759",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spoilers.json.gz\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d4b15a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "043724ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "23147241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utility data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['user_id'],d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "\n",
    "# Sort reviews per user by timestamp\n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "# Same for reviews per item\n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "742587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012-03-13',\n",
       " '2013-05-06',\n",
       " '2013-09-03',\n",
       " '2015-04-05',\n",
       " '2016-02-10',\n",
       " '2016-05-29']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.g. reviews for this user are sorted from earliest to most recent\n",
    "[d['timestamp'] for d in reviewsPerUser['b0d7e561ca59e313b728dc30a5b1862e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "bb364612",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "991fbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "ypred = []\n",
    "for d in reviewsPerUser:\n",
    "    ratings = []\n",
    "    reviews = reviewsPerUser[d]\n",
    "    if len(reviews) > 1:\n",
    "        for rating in reviews[:-1]:\n",
    "            ratings.append(rating['rating'])\n",
    "        y.append(reviews[-1]['rating'])\n",
    "        ypred.append(sum(ratings) / len(ratings))\n",
    "\n",
    "def MSE(y, ypred):\n",
    "    return sum([(a-b)**2 for (a,b) in zip(y,ypred)]) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "373cff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.970416294395752"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q1a'] = MSE(y,ypred)\n",
    "MSE(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bcd5ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c38c9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5131368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "ypred = []\n",
    "for d in reviewsPerItem:\n",
    "    ratings = []\n",
    "    reviews = reviewsPerItem[d]\n",
    "    if len(reviews) > 1:\n",
    "        for rating in reviews[:-1]:\n",
    "            ratings.append(rating['rating'])\n",
    "        y.append(reviews[-1]['rating'])\n",
    "        ypred.append(sum(ratings) / len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2cccbe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.051966103395068"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q1b'] = MSE(y,ypred)\n",
    "answers['Q1b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7288fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0abf5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bcd540f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.666035950804163, 2.1542691579943236, 2.0280931357090237]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q2'] = []\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    # etc.\n",
    "    y = []\n",
    "    ypred = []\n",
    "    for d in reviewsPerUser:\n",
    "        ratings = []\n",
    "        reviews = reviewsPerUser[d]\n",
    "        if len(reviews) > N:\n",
    "            for rating in reviews[-(N+1):-1]:\n",
    "                ratings.append(rating['rating'])\n",
    "            y.append(reviews[-1]['rating'])\n",
    "            ypred.append(sum(ratings) / len(ratings))\n",
    "        elif len(reviews) > 1:\n",
    "            for rating in reviews[:-1]:\n",
    "                ratings.append(rating['rating'])\n",
    "            y.append(reviews[-1]['rating'])\n",
    "            ypred.append(sum(ratings) / len(ratings))\n",
    "\n",
    "    answers['Q2'].append(MSE(y,ypred))\n",
    "\n",
    "answers['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e1b4ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "206c058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3ddd5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature3(N, u): # For a user u and a window size of N\n",
    "    feat = [1]\n",
    "    reviews = reviewsPerUser[u]\n",
    "    if len(reviews) > N:\n",
    "        for rating in reviews[-(N+1):-1]:\n",
    "            feat.append(rating['rating'])\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "05e622a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 4], [1, 4, 4, 4]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q3a'] = [feature3(2,dataset[0]['user_id']), feature3(3,dataset[0]['user_id'])]\n",
    "answers['Q3a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f839c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q3a']) == 2\n",
    "assert len(answers['Q3a'][0]) == 3\n",
    "assert len(answers['Q3a'][1]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "55691b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4146d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.560831912148225, 1.5409512373315772, 1.5396484853948436]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q3b'] = []\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    # etc.\n",
    "    x = []\n",
    "    y = []\n",
    "    mod = linear_model.LinearRegression()\n",
    "    ypred = []\n",
    "    for u in reviewsPerUser:\n",
    "        reviews = reviewsPerUser[u]\n",
    "        if len(reviews) > N:\n",
    "            x.append(feature3(N, u))\n",
    "            y.append(reviewsPerUser[u][-1]['rating'])\n",
    "\n",
    "    mod.fit(x, y)\n",
    "    ypred = mod.predict(x)\n",
    "    \n",
    "    mse = MSE(y, ypred)\n",
    "    answers['Q3b'].append(mse)\n",
    "\n",
    "answers['Q3b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d512b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3b'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1ba65fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4aab34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalAverage = [d['rating'] for d in dataset]\n",
    "globalAverage = sum(globalAverage) / len(globalAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2676be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMeanValue(N, u): # For a user u and a window size of N\n",
    "    feat = [1]\n",
    "    reviews = reviewsPerUser[u]\n",
    "    average = []\n",
    "    if len(reviews) > 1:\n",
    "        for i in range(2, min(N+2, len(reviews)+1)):\n",
    "            ni = -i\n",
    "            rating = reviews[-i]\n",
    "            feat.append(rating['rating'])\n",
    "            average.append(rating['rating'])\n",
    "\n",
    "        average = sum(average) / len(average)\n",
    "\n",
    "        while len(feat) < N+1:\n",
    "            feat.append(average)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "270cf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMissingValue(N, u):\n",
    "    feat = [1]\n",
    "    reviews = reviewsPerUser[u]\n",
    "    average = []\n",
    "    if len(reviews) > 1:\n",
    "        for i in range(2, min(N+2, len(reviews)+1)):\n",
    "            ni = -i\n",
    "            rating = reviews[-i]\n",
    "            feat.append(0)\n",
    "            feat.append(rating['rating'])\n",
    "            average.append(rating['rating'])\n",
    "\n",
    "        average = sum(average) / len(average)\n",
    "\n",
    "        while len(feat) < 2*N+1:\n",
    "            feat.append(1)\n",
    "            feat.append(0)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "58791bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       " [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4a'] = [featureMeanValue(10, dataset[0]['user_id']), featureMissingValue(10, dataset[0]['user_id'])]\n",
    "answers['Q4a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a3c28e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q4a']) == 2\n",
    "assert len(answers['Q4a'][0]) == 11\n",
    "assert len(answers['Q4a'][1]) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cbcee03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "73fabbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.53136743576524, 1.5164092454808245]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4b'] = []\n",
    "\n",
    "for featFunc in [featureMeanValue, featureMissingValue]:\n",
    "    # etc.\n",
    "    x = []\n",
    "    y = []\n",
    "    mod = linear_model.LinearRegression()\n",
    "    ypred = []\n",
    "    for u in reviewsPerUser:\n",
    "        reviews = reviewsPerUser[u]\n",
    "        if len(reviews) > 1:\n",
    "            x.append(featFunc(10, u))\n",
    "            y.append(reviewsPerUser[u][-1]['rating'])\n",
    "\n",
    "    mod.fit(x, y)\n",
    "    ypred = mod.predict(x)\n",
    "    \n",
    "    mse = MSE(y, ypred)\n",
    "    answers['Q4b'].append(mse)\n",
    "\n",
    "answers['Q4b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e348489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q4b\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c548e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1cee7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature5(sentence):\n",
    "    countExclama = 0\n",
    "    countCapital = 0\n",
    "\n",
    "    for alpha in sentence:\n",
    "        if alpha == '!':\n",
    "            countExclama = countExclama + 1\n",
    "        if alpha.isupper():\n",
    "            countCapital = countCapital + 1\n",
    "\n",
    "    return [1] + [len(sentence)] + [countExclama] + [countCapital]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "426ca2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    for spoiler,sentence in d['review_sentences']:\n",
    "        X.append(feature5(sentence))\n",
    "        y.append(spoiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "428bd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X, y)\n",
    "predictions = mod.predict(X)\n",
    "\n",
    "TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "\n",
    "TPR = TP/(TP + FN)\n",
    "TNR = TN/(TN + FP)\n",
    "\n",
    "BER = 1 - 1/2*(TPR + TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a94d7aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 121, 0, 4]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5a'] = X[0]\n",
    "answers['Q5a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "116c5b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2384, 168945, 86232, 3615, 0.4702652880062319]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5b'] = [TP, TN, FP, FN, BER]\n",
    "answers['Q5b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c0c96525",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q5a']) == 4\n",
    "assertFloatList(answers['Q5b'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f826e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "193e94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature6(review):\n",
    "    countExclama = 0\n",
    "    countCapital = 0\n",
    "    first5 = []\n",
    "\n",
    "    for spoiler,sentence in review['review_sentences'][:6]:\n",
    "        if len(first5) < 5:\n",
    "            first5.append(spoiler)\n",
    "        else:\n",
    "            for alpha in sentence:\n",
    "                if alpha == '!':\n",
    "                    countExclama = countExclama + 1\n",
    "                if alpha.isupper():\n",
    "                    countCapital = countCapital + 1\n",
    "\n",
    "    return [1] + first5 + [len(sentence)] + [countExclama] + [countCapital]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0a437dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n",
    "\n",
    "#etc.\n",
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X, y)\n",
    "predictions = mod.predict(X)\n",
    "\n",
    "TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "\n",
    "TPR = TP/(TP + FN)\n",
    "TNR = TN/(TN + FP)\n",
    "\n",
    "BER = 1 - 1/2*(TPR + TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c61a5fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 75, 0, 1]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6a'] = X[0]\n",
    "answers['Q6a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f977c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17050724637681158"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6b'] = BER\n",
    "answers['Q6b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f0be28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q6a']) == 9\n",
    "assertFloat(answers['Q6b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3bda0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "8c01c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50/25/25% train/valid/test split\n",
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c253fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bers = []\n",
    "bestC = 0.01\n",
    "ber = 100\n",
    "\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    # etc.\n",
    "    mod = linear_model.LogisticRegression(C=c, class_weight='balanced')\n",
    "    \n",
    "    mod.fit(Xtrain,ytrain)\n",
    "    ypredValid = mod.predict(Xvalid)\n",
    "    ypredTest = mod.predict(Xtest)\n",
    "\n",
    "    TP = sum([(a and b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    TN = sum([(not a and not b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    FP = sum([(not a and b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    FN = sum([(a and not b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    BER = 1 - 0.5*(TPR + TNR)\n",
    "\n",
    "    bers.append(BER)\n",
    "\n",
    "    if BER < ber:\n",
    "        bestC = c\n",
    "        ber = BER\n",
    "\n",
    "mod = linear_model.LogisticRegression(C=bestC, class_weight='balanced')\n",
    "mod.fit(Xtrain,ytrain)\n",
    "ypredTest = mod.predict(Xtest)\n",
    "\n",
    "TP = sum([(a and b) for (a,b) in zip(ytest, ypredTest)])\n",
    "TN = sum([(not a and not b) for (a,b) in zip(ytest, ypredTest)])\n",
    "FP = sum([(not a and b) for (a,b) in zip(ytest, ypredTest)])\n",
    "FN = sum([(a and not b) for (a,b) in zip(ytest, ypredTest)])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "\n",
    "ber = 1 - 0.5*(TPR + TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b8389608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1332802789146581,\n",
       " 0.13310974685463095,\n",
       " 0.14302713354555108,\n",
       " 0.14268606942549644,\n",
       " 0.14268606942549644,\n",
       " 0.1,\n",
       " 0.21265396110597345]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q7'] = bers + [bestC] + [ber]\n",
    "answers['Q7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1d53b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f06e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "38a6c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "57f30ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75/25% train/test split\n",
    "dataTrain = dataset[:15000]\n",
    "dataTest = dataset[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1d770bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utilities\n",
    "\n",
    "itemAverages = defaultdict(list)\n",
    "ratingMean = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    itemAverages[d['book_id']].append(d['rating'])\n",
    "    ratingMean.append(d['rating'])\n",
    "\n",
    "for i in itemAverages:\n",
    "    itemAverages[i] = sum(itemAverages[i]) / len(itemAverages[i])\n",
    "\n",
    "ratingMean = sum(ratingMean) / len(ratingMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "62952595",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for d in dataTrain:\n",
    "    u,i = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    usersPerItem[i].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4e0ab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From my HW2 solution, welcome to reuse\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "db0e1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in dataTest]\n",
    "labels = [d['rating'] for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e4891766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8164934412791371"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"Q8\"] = MSE(predictions, labels)\n",
    "answers[\"Q8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "789b53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers[\"Q8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0b298ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5930c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list0 = []\n",
    "list1to5 = []\n",
    "list5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b8b8ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataTest:\n",
    "    # etc.\n",
    "    item = d['book_id']\n",
    "    if len(usersPerItem[item]) > 5:\n",
    "        list5.append(d)\n",
    "    elif len(usersPerItem[item]) >= 1 and len(usersPerItem[item]) <= 5:\n",
    "        list1to5.append(d)\n",
    "    else:\n",
    "        list0.append(d)\n",
    "\n",
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in list0]\n",
    "labels = [d['rating'] for d in list0]\n",
    "mse0 = MSE(predictions, labels)\n",
    "\n",
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in list1to5]\n",
    "labels = [d['rating'] for d in list1to5]\n",
    "mse1to5 = MSE(predictions, labels)\n",
    "\n",
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in list5]\n",
    "labels = [d['rating'] for d in list5]\n",
    "mse5 = MSE(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a4664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d269238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.742012484444442, 2.052681872005889, 1.452063234864505]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"Q9\"] = [mse0, mse1to5, mse5]\n",
    "answers[\"Q9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ebfff50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q9\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0dbe10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e2fea856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "ratingMed = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    ratingMed.append(d['rating'])\n",
    "\n",
    "ratingMed = statistics.median(ratingMed)\n",
    "\n",
    "def predictRating2(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMed\n",
    "            \n",
    "list0 = []\n",
    "list1to5 = []\n",
    "list5 = []\n",
    "\n",
    "for d in dataTest:\n",
    "    # etc.\n",
    "    item = d['book_id']\n",
    "    if len(usersPerItem[item]) > 5:\n",
    "        list5.append(d)\n",
    "    elif len(usersPerItem[item]) >= 1 and len(usersPerItem[item]) <= 5:\n",
    "        list1to5.append(d)\n",
    "    else:\n",
    "        list0.append(d)\n",
    "\n",
    "predictions = [predictRating2(d['user_id'], d['book_id']) for d in list0]\n",
    "itsMSE = 1.7010\n",
    "labels = [d['rating'] for d in list0]\n",
    "mse = MSE(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "305d3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q10\"] = (\"describe your solution: I change the ratingMed that return in function predictRating to rating median.\", itsMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d0613500",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers[\"Q10\"][0]) == str\n",
    "assertFloat(answers[\"Q10\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "436d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c441f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
